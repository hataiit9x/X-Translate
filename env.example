# Server Configuration
PORT=3000

# Optional: Default LLM Configuration
# DEFAULT_LLM_BASE_URL=https://api.fireworks.ai/inference/v1
# DEFAULT_LLM_API_KEY=your_api_key_here
# DEFAULT_LLM_MODEL=accounts/fireworks/models/deepseek-v3p2
